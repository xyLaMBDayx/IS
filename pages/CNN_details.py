import streamlit as st

st.title("Cat and Dog Classfication")

st.write("This CNN Model classify between cats and dogs")
st.write("")
st.write("The Model consists of 23 layers (including input and output layer) which I will group it into 5 groups")
st.write("Input Layer : (32,32,3)")
st.write("1st Group : ")
st.write("1. Convolution Layer , output size : (32,32,3) , Perceptrons : 128")
st.write("2. Normalize Layer, output size : (30,30,32)")
st.write("3. Activation Layer : LeakyRelu,  output size : (30,30,32)")
st.write("4. Max Pooling Layer , output size : (15,15,32)")
st.write("2nd Group : ")
st.write("1. Convolution Layer , output size : (13, 13, 64) , Perceptrons : 256")
st.write("2. Normalize Layer, output size : (13, 13, 64)")
st.write("3. Activation Layer : LeakyRelu,  output size : (13, 13, 64)")
st.write("4. Max Pooling Layer , output size : (6, 6, 64)")
st.write("3rd Group : ")
st.write("1. Convolution Layer , output size : (4, 4, 128) , Perceptrons : 512")
st.write("2. Normalize Layer, output size : (4, 4, 128)")
st.write("3. Activation Layer : LeakyRelu,  output size : (4, 4, 128)")
st.write("4. Max Pooling Layer , output size : (2, 2, 128)")
st.write("5. Global Max Pooling Layer , output size : (128)")
st.write("---Fully Connected layer---")
st.write("4th Group : ")
st.write("1. Dense Layer , output size : (512) , Perceptrons : 512")
st.write("2. Normalize Layer, output size : (512)")
st.write("3. Activation Layer : LeakyRelu,  output size : (512)")
st.write("4. Dropout Layer , output size : (512)")
st.write("5th Group : ")
st.write("1. Dense Layer , output size : (128) , Perceptrons : 128")
st.write("2. Normalize Layer, output size : (128)")
st.write("3. Activation Layer : LeakyRelu,  output size : (128)")
st.write("4. Dropout Layer , output size : (128)")
st.write("Output Layer, Perceptrons : 2")

st.write("")
st.write("")
st.write("")
st.title("Dataset")
st.write("I use the dataset from oxford which I downloaded from tensorflow website")
st.write("Dataset Source : https://www.tensorflow.org/datasets/catalog/oxford_iiit_pet")
st.write("Which Consists of 3.7k train data and 3.7k test data which is a huge amount, so I decrease the numbers by 50%")

st.write("Small Disclaimer")
st.write("For this model, I actually plan to classify the breed of the cats and dogs too, but it takes too much time to train the model(15 minutes per epoch, with 50++ epochs) and the accuracy isn't high enough(30% approximately).")
st.write("So I decided to go for a minimal version by only classifying dogs or cats")